###### Import libraries #######
import os
from os import path
from glob import glob
import cooler
import numpy as np
import pandas as pd


localrules:
    all,
    make_differential_insulation,
    make_tads,
    call_loops_mustache,
    get_bed_data,
    get_cool_data,


###### Read config parameters #######

project_folder = config.get("project_folder", "results")
inputs_folder = config.get("inputs_folder", "inputs")
coolers_folder = config.get("coolers_folder", path.join(inputs_folder, "coolers"))
beds_folder = path.normpath(config.get("beds_folder", path.join(inputs_folder, "beds")))
beds_folder_name = path.basename(beds_folder)
bedpes_folder = path.normpath(config.get("bedpes_folder", path.join(inputs_folder, "bedpes")))
bedpes_folder_name = path.basename(bedpes_folder)
expected_folder = path.normpath(
    config.get("expected_folder", path.join(project_folder, "expected"))
)
pileups_folder = path.normpath(
    config.get("pileups_folder", path.join(project_folder, "pileups"))
)
eigenvectors_folder = path.normpath(
    config.get("eigenvectors_folder", path.join(project_folder, "eigenvectors"))
)
saddles_folder = path.normpath(
    config.get("saddles_folder", path.join(project_folder, "saddles"))
)
insulation_folder = path.normpath(
    config.get("insulation_folder", path.join(project_folder, "insulation"))
)
tad_folder = path.normpath(config.get("tad_folder", path.join(project_folder, "tads")))
tad_folder_name = path.basename(tad_folder)
loop_folder = path.normpath(
    config.get("loop_folder", path.join(project_folder, "loops"))
)
loop_folder_name = path.basename(loop_folder)
boundary_folder = path.normpath(
    config.get("boundary_folder", path.join(project_folder, "boundaries"))
)
boundary_folder_name = path.basename(boundary_folder)
loopability_folder = path.normpath(
    config.get("loopability_folder", path.join(project_folder, "loopability"))
)
loopability_folder_name = path.basename(loopability_folder)
outfolders = {
    tad_folder_name: tad_folder,
    loop_folder_name: loop_folder,
    boundary_folder_name: boundary_folder,
    beds_folder_name: beds_folder,
    loopability_folder_name: loopability_folder
}

### Input genome
genome = config["genome"]
chroms = pd.read_csv(
    f'{config["chromsizes"]}', sep="\t", names=["chrom", "start", "end"]
)["chrom"].values
chroms = list(filter(lambda x: x not in config.get("ignore_chroms", []), chroms))

### Input cool files
from urllib.parse import urlparse


def will_download(link):
    parsed_path = urlparse(link)
    return False if parsed_path.scheme == "" else True


samples_df = pd.read_csv(config["samples"], sep="\t", header=0, comment='#')
samples_df.loc[:, "will_download"] = samples_df.file.apply(will_download)
samples_df.loc[:, "local_path"] = samples_df.apply(
    lambda x: f"{coolers_folder}/{x['sample']}.mcool" if x.will_download else x["file"],
    axis=1,
)
samples_df = samples_df.set_index("sample")

samples = list(samples_df.index)
coollinks_dict = dict(
    samples_df.query("will_download")["file"]
)  # dict with cools to be downloaded
coolfiles_dict = dict(samples_df["local_path"])

### Input bed files
def get_files(folder, extension):
    files = list(map(path.basename, glob(f"{folder}/*{extension}")))
    return files
def make_local_path(bedname, kind):
    if kind == 'bed':
        return f"{beds_folder}/{bedname}.bed"
    elif kind == 'bedpe':
        return f"{bedpes_folder}/{bedname}.bedpe"
    else:
        raise ValueError('Only bed and bedpe file types are supported')

bedfiles_local = get_files(beds_folder, "bed")
bedpefiles_local = get_files(bedpes_folder, "bedpe")

local_bed_names = {path.splitext(bedfile)[0]:f'{beds_folder}/{bedfile}' for bedfile in bedfiles_local}
local_bedpe_names = {path.splitext(bedpefile)[0]:f'{bedpes_folder}/{bedpefile}' for bedpefile in bedpefiles_local}

bed_df = pd.read_csv(config["annotations"], sep="\t", header=0, comment='#')
bed_df.loc[:, "will_download"] = bed_df.file.apply(will_download)
bed_df.loc[:, "local_path"] = bed_df.apply(
    lambda x: make_local_path(x.bedname, x.format) if x.will_download else x.file, axis=1
)
bed_df = bed_df.set_index("bedname").replace('-', np.nan)
bed_df[['distal', 'by_distance', 'local', 'local_rescaled', 'loopability']] = ~bed_df[['distal', 'by_distance', 'local', 'local_rescaled', 'loopability']].isna()
bedlinks_dict = dict(
    bed_df.query("will_download")["file"]
)  # dict with beds to be downloaded
bedfiles_dict = dict(bed_df['local_path'])
bedfiles_dict.update(local_bed_names)
bedfiles_dict.update(local_bedpe_names)
bedfiles = list(bedfiles_dict.keys())
# bedfiles_pileups = [bf for bf in bedfiles if bed_df.loc[bf, 'pileups']]
bedtype_dict = dict(bed_df['format'])
# bedpe_pileups_mindist, bedpe_pileups_maxdist = config['bedpe_pileups_distance_limits']

samples_annotations = ~pd.read_csv(config['samples_annotations_combinations'],
sep='\t', header=0, index_col=0, comment='#').isna()
### Data resolutions
ignore_resolutions_more_than = config["ignore_resolutions_more_than"]
resolutions = config["resolutions"]  ##### Assume same resolutions in all coolers
minresolution = min(resolutions)
resolutions = list(filter(lambda x: x <= ignore_resolutions_more_than, resolutions))

if config["eigenvector"]["do"]:
    eigenvector_resolution_limits = config["eigenvector"]["resolution_limits"]
    eigenvector_resolutions = list(
        filter(
            lambda x: eigenvector_resolution_limits[0]
            <= x
            <= eigenvector_resolution_limits[1],
            resolutions,
        )
    )

if config["saddle"]["do"]:
    saddle_mindist, saddle_maxdist = config["saddle"]["distance_limits"]
    saddle_mindists = [
        int(saddle_mindist * 2 ** i)
        for i in np.arange(0, np.log2(saddle_maxdist / saddle_mindist))
    ]
    saddle_separations = [f"_dist_{mindist}-{mindist*2}" for mindist in saddle_mindists]

if config["pileups"]["do"] or config["pileups"]["bed_pairs"]["do"]:
    shifts = config["pileups"]["shifts"]
    pileup_resolution_limits = config["pileups"]["resolution_limits"]
    pileups_mindist, pileups_maxdist = config["pileups"]["distance_limits"]
    pileup_resolutions = list(
        filter(
            lambda x: pileup_resolution_limits[0] <= x <= pileup_resolution_limits[1],
            resolutions,
        )
    )
    mindists = [
        int(pileups_mindist * 2 ** i)
        for i in np.arange(0, np.log2(pileups_maxdist / pileups_mindist))
    ]
    separations = [f"_dist_{mindist}-{mindist*2}" for mindist in mindists]

if config["pileups"]["bed_pairs"]["do"]:
    bedpairs_folder = path.normpath(config["pileups"]["bed_pairs"]["path"])
    bedpairs_folder_name = path.basename(bedpairs_folder)

    def get_pairs(bedpairs_input_dict):
        return bedpairs_input_dict["files"]

    bedpairs = {
        name: config["pileups"]["bed_pairs"]["input"][name]["files"]
        for name in config["pileups"]["bed_pairs"]["input"].keys()
    }
    bedpairs_args = {
        name: " " + config["pileups"]["bed_pairs"]["input"][name]["arguments"]
        for name in config["pileups"]["bed_pairs"]["input"].keys()
    }

if config["loopability"]["do"]:
    loopability_args = config["loopability"]["arguments"]
    loopability_shifts = config["loopability"]["shifts"]

if config["insulation"]["do"]:
    insul_res_win = []
    for resolution in config["insulation"]["resolutions"]:
        for win in config["insulation"]["resolutions"][resolution]:
            insul_res_win.append(f"{resolution}_{win}")

if config["call_TADs"]["do"]:
    tad_res_win = []
    for resolution in config["call_TADs"]["resolutions"]:
        for win in config["call_TADs"]["resolutions"][resolution]:
            tad_res_win.append(f"{resolution}_{win}")

# chroms = cooler.Cooler(f'{coolers_folder}/{coolfiles[0]}::resolutions/{resolutions[0]}').chroms()[:]

# bedpe_mindists = [int(bedpe_pileups_mindist*2**i) for i in np.arange(0, np.log2(bedpe_pileups_maxdist/bedpe_pileups_mindist))]
# bedpe_separations = [f'{mindist}-{mindist*2}' for mindist in bedpe_mindists]

diff_boundaries = (
    expand(
        f"{boundary_folder}/Insulation_{config['compare_boundaries']['samples'][0]}_not_"
        f"{config['compare_boundaries']['samples'][1]}_{{insul_res_win}}.bed",
        insul_res_win=insul_res_win,
    )
    if config["compare_boundaries"]["do"]
    else []
)
diff_boundaries_pileups = (
    expand(
        f"{pileups_folder}/{boundary_folder_name}/{{sample}}-{{resolution}}_over_Insulation_{config['compare_boundaries']['samples'][0]}_not_"
        f"{config['compare_boundaries']['samples'][1]}_{{insul_res_win}}.bed_{{norm}}_local.np.txt",
        sample=samples,
        resolution=pileup_resolutions,
        insul_res_win=insul_res_win,
        norm=["expected", f"{shifts}-shifts"],
    )
    if config["compare_boundaries"]["do"] and config["pileups"]["do"]
    else []
)

tads = (
    expand(
        f"{tad_folder}/TADs_{{sampleTADs}}_{{tad_res_win}}.bed",
        sampleTADs=config["call_TADs"]["samples"],
        tad_res_win=tad_res_win,
    )
    if config["call_TADs"]["do"]
    else []
)

tads_pileups = (
    expand(
        f"{pileups_folder}/{tad_folder_name}/{{sample}}-{{resolution}}_over_TADs_{{sampleTADs}}_{{tad_res_win}}_{{norm}}_local_rescaled.np.txt",
        sample=samples,
        resolution=pileup_resolutions,
        sampleTADs=config["call_TADs"]["samples"],
        tad_res_win=tad_res_win,
        norm=["expected", f"{shifts}-shifts"],
    )
    if config["call_TADs"]["do"] and config["pileups"]["do"]
    else []
)
dot_methods = [
    m for m in config["call_dots"]["methods"] if config["call_dots"]["methods"][m]["do"]
]
if dot_methods:
    loops = expand(
        f"{loop_folder}/Loops_{{method}}_{{sampleLoops}}_{{resolutionLoops}}.bedpe",
        method=dot_methods,
        sampleLoops=config["call_dots"]["samples"],
        resolutionLoops=config["call_dots"]["resolution"],
    )

    loops_pileups = (
        expand(
            f"{pileups_folder}/{loop_folder_name}/{{sample}}-{{resolution}}_over_Loops_{{method}}_{{sampleLoops}}_{{resolutionLoops}}_{{norm}}{{mode}}.np.txt",
            sample=samples,
            resolution=pileup_resolutions,
            method=dot_methods,
            sampleLoops=config["call_dots"]["samples"],
            resolutionLoops=config["call_dots"]["resolution"],
            norm=["expected", f"{shifts}-shifts"],
            mode=[""] + separations,
        )
        if config["pileups"]["do"]
        else []
    )
else:
    loops = []
    loops_pileups = []

for file in loops:
    name = path.splitext(path.basename(file))[0]
    bedfiles_dict[name] = file
    bedtype_dict[name] = 'bedpe'
for file in tads + diff_boundaries:
    name = path.splitext(path.basename(file))[0]
    bedfiles_dict[name] = file
    bedtype_dict[name] = 'bed'

beds_pileups = []
if config["pileups"]["do"]:
    for bedname, row in bed_df.iterrows():
        modes = []
        if row.distal:
            modes += ['']
        if row.by_distance:
            modes += separations
        if row.local:
            modes += ['_local']
        if row.local_rescaled:
            modes += ['_local_rescaled']
        for sample in samples:
            if sample not in samples_annotations.index:
                continue
            if bedname in samples_annotations.columns  and not samples_annotations.loc[sample, bedname]:
                continue
            beds_pileups += expand(
                f"{pileups_folder}/{beds_folder_name}/{sample}-{{resolution}}_over_{bedname}_{{norm}}{{mode}}.np.txt",

                resolution=pileup_resolutions,
                norm=["expected", f"{shifts}-shifts"],
                mode=modes,
            )

paired_beds_pileups = (
    expand(
        f"{pileups_folder}/{bedpairs_folder_name}/{{sample}}-{{resolution}}_over-paired_{{pairname}}_{{norm}}{{mode}}.np.txt",
        sample=samples,
        resolution=pileup_resolutions,
        pairname=bedpairs.keys(),
        separation=separations,
        norm=["expected", f"{shifts}-shifts"],
        mode=[""] + separations,
    )
    if config["pileups"]["do"] and config["pileups"]["bed_pairs"]["do"]
    else []
)
loopability_tables = []
if config["loopability"]["do"]:
    for bedname, row in bed_df.iterrows():
        if row.loopability:
            for sample in samples:
                if sample not in samples_annotations.index:
                    continue
                if bedname in samples_annotations.columns and not samples_annotations.loc[sample, bedname]:
                    continue
                loopability_tables += expand(
                        f"{loopability_folder}/{sample}-{{resolution}}_over_{bedname}_{{norm}}_loopability_seed{{seed}}_{{args}}.tsv",
                        resolution=config["loopability"]["resolutions"],
                        norm=["expected", f"{loopability_shifts}-shifts"],
                        seed=np.arange(config["loopability"]["n_random_samples"]),
                        args=list(loopability_args.keys()),
                    )
saddles = (
    expand(
        f"{saddles_folder}/{{sample}}_{{resolution}}_{{bins}}{{dist}}.{{ending}}",
        sample=samples,
        resolution=eigenvector_resolutions,
        bins=config["saddle"]["bins"],
        dist=saddle_separations + [""],
        ending=["saddledump.npz", "digitized.tsv"],
    )
    if config["saddle"]["do"]
    else []
)


def split_dist(dist_wildcard, mindist_arg="--mindist", maxdist_arg="--maxdist"):
    if dist_wildcard == "":
        return ""
    else:
        assert dist_wildcard.startswith("_dist_")
        dists = dist_wildcard.split("_")[-1]
        mindist, maxdist = dists.split("-")
        return f"{mindist_arg} {mindist} {maxdist_arg} {maxdist}"



###### Define rules #######
rule all:
    input:
        lambda wildcards: diff_boundaries,
        lambda wildcards: diff_boundaries_pileups,
        lambda wildcards: tads,
        lambda wildcards: tads_pileups,
        lambda wildcards: loops,
        lambda wildcards: loops_pileups,
        lambda wildcards: beds_pileups,
        lambda wildcards: paired_beds_pileups,
        lambda wildcards: loopability_tables,
        lambda wildcards: saddles,


rule make_pileups:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        expected=f"{expected_folder}/{{sample}}_{{resolution}}.expected.tsv",
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedfile],
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedfile}}_expected.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
        format=lambda wildcards: bedtype_dict[wildcards.bedfile],
    threads: 8
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype {{params.format}} --n_proc {{threads}} --expected {{input.expected}} --outdir {{params.outdir}} --outname {{params.outname}}"


rule make_pileups_local:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        expected=f"{expected_folder}/{{sample}}_{{resolution}}.expected.tsv",
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedfile],
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedfile}}_expected_local.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype bed --local --n_proc {{threads}} --expected {{input.expected}} --outdir {{params.outdir}} --outname {{params.outname}}"


rule make_pileups_local_rescaled:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        expected=f"{expected_folder}/{{sample}}_{{resolution}}.expected.tsv",
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedfile],
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedfile}}_expected_local_rescaled.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype bed --local --rescale --rescale_pad {config['pileups']['rescale_pad']} --n_proc {{threads}} --expected {{input.expected}} --outdir {{params.outdir}} --outname {{params.outname}}"


rule make_pileups_distance:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        expected=f"{expected_folder}/{{sample}}_{{resolution}}.expected.tsv",
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedfile],
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedfile}}_expected_dist_{{mindist,[0-9]+}}-{{maxdist,[0-9]+}}.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
        format=lambda wildcards: bedtype_dict[wildcards.bedfile],
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype {{params.format}} --basetype {{params.format}} --n_proc {{threads}} --expected {{input.expected}} --mindist {{wildcards.mindist}} --maxdist {{wildcards.maxdist}} --outdir {{params.outdir}} --outname {{params.outname}}"


rule loopability:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        expected=f"{expected_folder}/{{sample}}_{{resolution}}.expected.tsv",
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedname],
    output:
        f"{loopability_folder}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedname}}_expected_loopability_seed{{seed,[0-9]+}}_{{args}}.tsv",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        args=lambda wildcards: loopability_args[wildcards.args]
    threads: 8
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype bed --by_window --seed {{wildcards.seed}} --n_proc {{threads}} --expected {{input.expected}} --outdir {{loopability_folder}} --outname {{params.outname}} {{params.args}}"


rule loopability_shifts:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedname],
    output:
        f"{loopability_folder}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedname}}_{{loopability_shifts}}-shifts_loopability_seed{{seed,[0-9]+}}_{{args}}.tsv",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        args=lambda wildcards: loopability_args[wildcards.args]
    threads: 8
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype bed --by_window --seed {{wildcards.seed}} --n_proc {{threads}} --nshifts {{wildcards.loopability_shifts}} --outdir {{loopability_folder}} --outname {{params.outname}} {{params.args}}"


rule make_pileups_shifts:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedfile],
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedfile}}_{shifts}-shifts.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
        format=lambda wildcards: bedtype_dict[wildcards.bedfile],
    threads: 8
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype {{params.format}} --n_proc {{threads}} --nshifts {shifts} --outdir {{params.outdir}} --outname {{params.outname}}"


rule make_pileups_shifts_local:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedfile],
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedfile}}_{shifts}-shifts_local.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype bed --local --n_proc {{threads}} --nshifts {shifts} --outdir {{params.outdir}} --outname {{params.outname}}"


rule make_pileups_shifts_local_rescaled:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedfile],
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedfile}}_{shifts}-shifts_local_rescaled.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype bed --local --rescale --rescale_pad {config['pileups']['rescale_pad']} --n_proc {{threads}} --nshifts {shifts} --outdir {{params.outdir}} --outname {{params.outname}}"


rule make_pileups_shifts_distance:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        bedfile=lambda wildcards: bedfiles_dict[wildcards.bedfile],
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over_{{bedfile}}_{shifts}-shifts_dist_{{mindist,[0-9]+}}-{{maxdist,[0-9]+}}.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
        format=lambda wildcards: bedtype_dict[wildcards.bedfile],
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bedfile}} --basetype {{params.format}} --n_proc {{threads}} --nshifts {shifts} --mindist {{wildcards.mindist}} --maxdist {{wildcards.maxdist}} --outdir {{params.outdir}} --outname {{params.outname}}"


rule make_pileups_bed2:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        expected=f"{expected_folder}/{{sample}}_{{resolution}}.expected.tsv",
        bed1=lambda wildcards: path.join(
            bedpairs_folder, bedpairs[wildcards.pairname][0]
        ),
        bed2=lambda wildcards: path.join(
            bedpairs_folder, bedpairs[wildcards.pairname][1]
        ),
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over-paired_{{pairname}}_expected.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{bedpairs_folder_name}",
        args=lambda wildcards: bedpairs_args[wildcards.pairname],
    threads: 8
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bed1}} --basetype bed --bed2 {{input.bed2}} --n_proc {{threads}} --expected {{input.expected}} --outdir {{params.outdir}} --outname {{params.outname}} {{params.args}}"


rule make_pileups_bed2_distance:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        expected=f"{expected_folder}/{{sample}}_{{resolution}}.expected.tsv",
        bed1=lambda wildcards: path.join(
            bedpairs_folder, bedpairs[wildcards.pairname][0]
        ),
        bed2=lambda wildcards: path.join(
            bedpairs_folder, bedpairs[wildcards.pairname][1]
        ),
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over-paired_{{pairname}}_expected_dist_{{mindist,[0-9]+}}-{{maxdist,[0-9]+}}.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
        args=lambda wildcards: bedpairs_args[wildcards.pairname],
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bed1}} --basetype bed --bed2 {{input.bed2}} --n_proc {{threads}} --expected {{input.expected}} --mindist {{wildcards.mindist}} --maxdist {{wildcards.maxdist}} --outdir {{params.outdir}} --outname {{params.outname}} {{params.args}}"


rule make_pileups_bed2_shifts:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        bed1=lambda wildcards: path.join(
            bedpairs_folder, bedpairs[wildcards.pairname][0]
        ),
        bed2=lambda wildcards: path.join(
            bedpairs_folder, bedpairs[wildcards.pairname][1]
        ),
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over-paired_{{pairname}}_{shifts}-shifts.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
        args=lambda wildcards: bedpairs_args[wildcards.pairname],
    threads: 8
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bed1}} --basetype bed --bed2 {{input.bed2}} --n_proc {{threads}} --nshifts {shifts} --outdir {{params.outdir}} --outname {{params.outname}} {{params.args}}"


rule make_pileups_bed2_shifts_distance:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
        bed1=lambda wildcards: path.join(
            bedpairs_folder, bedpairs[wildcards.pairname][0]
        ),
        bed2=lambda wildcards: path.join(
            bedpairs_folder, bedpairs[wildcards.pairname][1]
        ),
    output:
        f"{pileups_folder}/{{folder}}/{{sample}}-{{resolution,[0-9]+}}_over-paired_{{pairname}}_{shifts}-shifts_dist_{{mindist,[0-9]+}}-{{maxdist,[0-9]+}}.np.txt",
    params:
        outname=lambda wildcards, output: output[0].split("/")[-1],
        outdir=lambda wildcards, output: f"{pileups_folder}/{wildcards.folder}",
        args=lambda wildcards: bedpairs_args[wildcards.pairname],
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"coolpup.py {{input.cooler}}::resolutions/{{wildcards.resolution}} {{input.bed1}} --basetype bed --bed2 {{input.bed2}} --n_proc {{threads}} --nshifts {shifts} --mindist {{wildcards.mindist}} --maxdist {{wildcards.maxdist}} --outdir {{params.outdir}} --outname {{params.outname}} {{params.args}}"


rule call_loops_chromosight:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
    output:
        f"{loop_folder}/Loops_chromosight_{{sample}}_{{resolution,[0-9]+}}.bedpe",
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    shell:
        f"chromosight detect --pattern loops --no-plotting -t {{threads}} {{input.cooler}}::resolutions/{{wildcards.resolution}} {loop_folder}/loops_chromosight_{{wildcards.sample}}_{{wildcards.resolution}} &&"
        f"tail -n +2 {loop_folder}/loops_chromosight_{{wildcards.sample}}_{{wildcards.resolution}}.tsv | cut -f1-6 > {{output}}"



rule call_loops_mustache_chrom:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
    output:
        temp(
            f"{loop_folder}/Mustache_bychr/Loops_mustache_{{sample}}_{{resolution,[0-9]+}}_{{chrom}}.bedpe"
        ),
    threads: 4
    params:
        args=config["call_dots"]["methods"]["mustache"]["arguments"],
        dist=config["call_dots"]["methods"]["mustache"]["max_dist"],
    resources:
        mem_mb=lambda wildcards, threads: threads * 16 * 1024,
        runtime=24 * 60,
    conda:
        "envs/mustache_env.yml"
    shell:
        f"python3 -m mustache -p {{threads}} -f {{input.cooler}} -r {{wildcards.resolution}} "
        f"-ch {{wildcards.chrom}} -d {{params.dist}} {{params.args}} -o {{output}}"


rule call_loops_mustache:
    input:
        lambda wildcards: [
            f"{loop_folder}/Mustache_bychr/Loops_mustache_{{sample}}_{{resolution,[0-9]+}}_{chrom}.bedpe"
            for chrom in chroms
        ],
    output:
        f"{loop_folder}/Loops_mustache_{{sample}}_{{resolution,[0-9]+}}.bedpe",
    resources:
        mem_mb=1024,
        runtime=60,
    shell:
        f"awk 'FNR-1' {{input}} | cut -f1-6 > {{output}}"


rule make_differential_insulation:
    input:
        insulation_WT=(
            f"{insulation_folder}/{{sampleWT}}_{{resolution}}_{{window}}.insulation.tsv"
        ),
        insulation_KO=(
            f"{insulation_folder}/{{sampleKO}}_{{resolution}}_{{window}}.insulation.tsv"
        ),
    output:
        f"{boundary_folder}/Insulation_{{sampleWT}}_not_{{sampleKO}}_{{resolution,[0-9]+}}_{{window,[0-9]+}}.bed",
    threads: 1
    resources:
        mem_mb=1024,
        runtime=60,
    run:
        from skimage.filters import threshold_li, threshold_otsu

        if config["insulation"]["strength_threshold"] == "Li":
            thresholding_fun = threshold_li
        elif config["insulation"]["strength_threshold"] == "Otsu":
            thresholding_fun = threshold_otsu
        else:
            try:
                thr = float(config["insulation"]["strength_threshold"])
                thresholding_fun = lambda x: thr
            except ValueError:
                raise ValueError(
                    "Insulating boundary strength threshold can be Li, Otsu or a float"
                )
        insWT = pd.read_csv(input.insulation_WT, sep="\t")
        insWT = insWT[~insWT["is_bad_bin"]].drop(columns=["is_bad_bin"])
        insKO = pd.read_csv(input.insulation_KO, sep="\t")
        insKO = insKO[~insKO["is_bad_bin"]].drop(columns=["is_bad_bin"])
        ins = pd.merge(
            insWT, insKO, suffixes=("WT", "KO"), on=["chrom", "start", "end"]
        )
        diff_ins = ins[
            (
                ins[f"boundary_strength_{wildcards.window}WT"]
                / ins[f"boundary_strength_{wildcards.window}KO"]
                >= config["compare_boundaries"]["fold_change_threshold"]
            )
            | (
                (
                    ins[f"boundary_strength_{wildcards.window}WT"]
                    > thresholding_fun(
                        insWT[f"boundary_strength_{wildcards.window}"].dropna().values
                    )
                )
                & np.isnan(ins[f"boundary_strength_{wildcards.window}KO"])
            )
        ]
        diff_ins[["chrom", "start", "end"]].to_csv(
            output[0], header=False, index=False, sep="\t"
        )


rule make_tads:
    input:
        insulation=(
            f"{insulation_folder}/{{sample}}_{{resolution}}_{{window}}.insulation.tsv"
        ),
    output:
        f"{tad_folder}/TADs_{{sample}}_{{resolution,[0-9]+}}_{{window,[0-9]+}}.bed",
    threads: 1
    resources:
        mem_mb=1024,
        runtime=60,
    run:
        from skimage.filters import threshold_li, threshold_otsu

        if config["insulation"]["strength_threshold"] == "Li":
            thresholding_fun = threshold_li
        elif config["insulation"]["strength_threshold"] == "Otsu":
            thresholding_fun = threshold_otsu
        else:
            try:
                thr = float(config["insulation"]["strength_threshold"])
                thresholding_fun = lambda x: thr
            except ValueError:
                raise ValueError(
                    "Insulating boundary strength threshold can be Li, Otsu or a float"
                )

        ins = pd.read_csv(input.insulation, sep="\t")
        ins = ins[~ins["is_bad_bin"]].drop(columns=["is_bad_bin"])
        ins = ins[
            ins[f"boundary_strength_{wildcards.window}"]
            > thresholding_fun(
                ins[f"boundary_strength_{wildcards.window}"].dropna().values
            )
        ][["chrom", "start", "end"]]
        tads = (
            ins.groupby("chrom")
            .apply(
                lambda x: pd.concat(
                    [x[:-1].reset_index(drop=True), x[1:].reset_index(drop=True)],
                    axis=1,
                    ignore_index=True,
                )
            )
            .reset_index(drop=True)
        )
        tads.columns = [["chrom1", "start1", "end1", "chrom2", "start2", "end2"]]
        tads.columns = tads.columns.get_level_values(0)
        tads = tads[
            (tads["start2"] - tads["start1"]) <= config["call_TADs"]["max_tad_length"]
        ].reset_index(drop=True)
        tads["start"] = (tads["start1"] + tads["end1"]) // 2
        tads["end"] = (tads["start2"] + tads["end2"]) // 2
        tads = tads[["chrom1", "start", "end"]]
        tads.to_csv(output[0], header=False, index=False, sep="\t")


rule make_insulation:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
    output:
        f"{insulation_folder}/{{sample}}_{{resolution,[0-9]+}}_{{window,[0-9]+}}.insulation.tsv",
    params:
        chunksize=lambda wildcards: config["insulation"].get("chunksize", 20000000),
    threads: 1
    resources:
        mem_mb=32 * 1024,
        runtime=240,
    shell:
        "cooltools diamond-insulation {input.cooler}::resolutions/{wildcards.resolution} {wildcards.window} --chunksize {params.chunksize} > {output}"


rule make_saddles:
    input:
        eigenvector=(
            f"{eigenvectors_folder}/{{sample}}_{{resolution}}_eigenvectors.cis.vecs.tsv"
        ),
        expected=f"{expected_folder}/{{sample}}_{{resolution}}.expected.tsv",
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
    output:
        saddle=f"{saddles_folder}/{{sample}}_{{resolution,[0-9]+}}_{{bins,[0-9]+}}{{dist,.*}}.saddledump.npz",
        digitized=f"{saddles_folder}/{{sample}}_{{resolution,[0-9]+}}_{{bins,[0-9]+}}{{dist,.*}}.digitized.tsv",
    params:
        prefix=lambda wildcards, output: output["saddle"][:-15],
        distargs=lambda wildcards: split_dist(
            wildcards.dist, "--min-dist", "--max-dist"
        ),
        args=config["saddle"]["args"],
    threads: 1
    resources:
        mem_mb=8 * 1024,
        runtime=60,
    shell:
        "cooltools compute-saddle -o {params.prefix} {params.args} {params.distargs} {input.cooler}::resolutions/{wildcards.resolution} {input.eigenvector} {input.expected}"


rule make_expected:
    input:
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
    output:
        f"{expected_folder}/{{sample}}_{{resolution,[0-9]+}}.expected.tsv",
    threads: 4
    resources:
        mem_mb=lambda wildcards, threads: threads * 8 * 1024,
        runtime=60,
    shell:
        "cooltools compute-expected -p {threads} {input.cooler}::resolutions/{wildcards.resolution} --ignore-diags 0 -o {output}"


rule make_eigenvectors:
    input:
        reftrack=(
            f'{config["path_genome_folder"]}/gc/{genome}_{{resolution}}_gc.bedgraph'
        ),
        cooler=lambda wildcards: coolfiles_dict[wildcards.sample],
    output:
        f"{eigenvectors_folder}/{{sample}}_{{resolution,[0-9]+}}_eigenvectors.cis.vecs.tsv",
        f"{eigenvectors_folder}/{{sample}}_{{resolution,[0-9]+}}_eigenvectors.cis.lam.txt",
        f"{eigenvectors_folder}/{{sample}}_{{resolution,[0-9]+}}_eigenvectors.cis.bw",
    params:
        prefix=lambda wildcards, output: output[0][:-13],
    threads: 1
    resources:
        mem_mb=8 * 1024,
        runtime=60,
    shell:
        "cooltools call-compartments --reference-track {input.reftrack} --bigwig {input.cooler}::resolutions/{wildcards.resolution} -o {params.prefix}"


rule make_gc:
    input:
        fasta=f'{config["path_genome_fasta"]}',
        bins=f'{config["path_genome_folder"]}/bins/{genome}_{{resolution}}_bins.bed',
    output:
        f'{config["path_genome_folder"]}/gc/{genome}_{{resolution,[0-9]+}}_gc.bedgraph',
    threads: 1
    resources:
        mem_mb=8 * 1024,
        runtime=60,
    shell:
        "cooltools genome gc {input.bins} {input.fasta} > {output}"


rule make_bins:
    input:
        chromsizes=f'{config["chromsizes"]}',
    output:
        f'{config["path_genome_folder"]}/bins/{genome}_{{resolution,[0-9]+}}_bins.bed',
    threads: 1
    resources:
        mem_mb=8 * 1024,
        runtime=60,
    shell:
        "cooltools genome binnify {input} {wildcards.resolution} > {output}"


def download_file(file, local_filename):
    import requests
    import tqdm
    import re

    with requests.get(file, stream=True) as r:
        ext_gz = (
            ".gz"
            if re.findall("filename=(.+)", r.headers["content-disposition"])[
                0
            ].endswith(".gz")
            else ""
        )
        r.raise_for_status()
        print("downloading:", file, "as ", local_filename + ext_gz)
        with open(local_filename + ext_gz, "wb") as f:
            for chunk in tqdm.tqdm(r.iter_content(chunk_size=8192)):
                f.write(chunk)
    return local_filename + ext_gz


def get_file(file, output):
    """
    If input is URL, it download via python's requests. Uncompress if needed.
    """
    if file == output:
        exit()

    from urllib.parse import urlparse

    parsed_path = urlparse(file)
    if parsed_path.scheme == "http" or parsed_path.scheme == "https":
        output_file = download_file(file, output)
    else:
        raise Exception(
            f"Unable to download from: {file}\nScheme {parsed_url.scheme} is not supported"
        )
    if output_file.endswith(".gz"):
        shell(f"gzip -d {output_file}")


rule get_cool_data:
    output:
        f"{coolers_folder}/{{sample}}.mcool",
    threads: 1
    resources:
        mem_mb=256,
        runtime=60,
    params:
        file=lambda wildcards: coollinks_dict[wildcards.sample],
    run:
        get_file(str(params.file), str(output))

rule get_bedpe_data:
    output:
        f"{bedpes_folder}/{{bedname}}.bedpe",
    threads: 1
    resources:
        mem_mb=256,
        runtime=60,
    params:
        file=lambda wildcards: bedlinks_dict[wildcards.bedname],
    run:
        get_file(str(params.file), str(output))

rule get_bed_data:
    output:
        f"{beds_folder}/{{bedname}}.bed",
    threads: 1
    resources:
        mem_mb=256,
        runtime=60,
    params:
        file=lambda wildcards: bedlinks_dict[wildcards.bedname],
    run:
        get_file(str(params.file), str(output))
